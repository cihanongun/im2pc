{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!wget https://shapenet.cs.stanford.edu/ericyi/shapenetcore_partanno_segmentation_benchmark_v0.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import utils\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import models\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "log_folder = \"logs/\" # folder path to save the results\n",
    "save_results = True # save the results to log_folder\n",
    "use_GPU = True # use GPU, False to use CPU\n",
    "latent_size = 128 # bottleneck size of the Autoencoder model\n",
    "use_TB = False\n",
    "\n",
    "if(save_results):\n",
    "    utils.clear_folder(log_folder)\n",
    "    log_file = open(log_folder +\"logs.txt\" ,\"a\") # open log file\n",
    "if(use_TB):\n",
    "    writer = SummaryWriter(log_folder + \"TB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2658, 2048, 3)\n",
      "(2658, 224, 224, 3)\n",
      "(396, 2048, 3)\n",
      "(396, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "from Dataset import get_dataset\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "category = \"Chair\"\n",
    "point_size = 2048\n",
    "image_resolution = 224\n",
    "\n",
    "train_pc, train_im = get_dataset(category, \"train\", point_size, image_resolution)\n",
    "val_pc, val_im = get_dataset(category, \"validation\", point_size, image_resolution)\n",
    "#train_pc = np.load(\"data/train_pc.npy\")\n",
    "#train_im = np.load(\"data/train_im.npy\")\n",
    "#val_pc = np.load(\"data/val_pc.npy\")\n",
    "#val_im = np.load(\"data/val_im.npy\")\n",
    "\n",
    "train_pc = train_pc[:,:,0:3]\n",
    "val_pc = val_pc[:,:,0:3]\n",
    "train_im /= 255.0\n",
    "val_im /= 255.0\n",
    "\n",
    "print(train_pc.shape)\n",
    "print(train_im.shape)\n",
    "print(val_pc.shape)\n",
    "print(val_im.shape)\n",
    "\n",
    "train_pc_tensor = torch.from_numpy(train_pc).float()\n",
    "train_im_tensor = torch.from_numpy(train_im).float()\n",
    "val_pc_tensor = torch.from_numpy(val_pc).float()\n",
    "val_im_tensor = torch.from_numpy(val_im).float()\n",
    "\n",
    "train_set = TensorDataset(train_im_tensor, train_pc_tensor)\n",
    "val_set = TensorDataset(val_im_tensor, val_pc_tensor)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_set , batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "val_loader = DataLoader(dataset=val_set, batch_size=batch_size, shuffle=True,  pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IMtoPC(\n",
       "  (vgg): Vgg16(\n",
       "    (conv1_1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv1_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv2_1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv2_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv3_1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv3_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv3_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv4_1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv4_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv4_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv5_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv5_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv5_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (fc1): Linear(in_features=25088, out_features=128, bias=True)\n",
       "  (dec1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "  (dec2): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "  (dec3): Linear(in_features=2048, out_features=6144, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.IMtoPC(latent_size, point_size)\n",
    "device = torch.device(\"cuda:0\")\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch3d.loss import chamfer_distance # chamfer distance for calculating point cloud distance\n",
    "\n",
    "def rec_criterion(pc1, pc2):\n",
    "    loss, _ = chamfer_distance(pc1, pc2)\n",
    "    return loss\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch():\n",
    "    \n",
    "    model.train()\n",
    "    t_rec_loss = []\n",
    "    \n",
    "    for i, data in enumerate(train_loader):\n",
    "        model.zero_grad()\n",
    "        \n",
    "        im_batch = data[0].to(device)\n",
    "        pc_batch = data[1].to(device)\n",
    "        \n",
    "        output = model(im_batch)\n",
    "        rec_loss = rec_criterion(pc_batch, output)\n",
    "            \n",
    "        rec_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        t_rec_loss.append(rec_loss.item())\n",
    "\n",
    "    return np.mean(t_rec_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch():\n",
    "    \n",
    "    model.eval()\n",
    "    t_rec_loss = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, data in enumerate(val_loader):\n",
    "              \n",
    "            im_batch = data[0].to(device)\n",
    "            pc_batch = data[1].to(device)\n",
    "\n",
    "            output = model(im_batch)\n",
    "            \n",
    "            rec_loss = rec_criterion(pc_batch, output)\n",
    "            t_rec_loss.append(rec_loss.item())\n",
    "\n",
    "    return np.mean(t_rec_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def test_epoch(epoch_n):\n",
    "    \n",
    "    t_rec_loss, t_seg_loss , t_accuracy = 0,0,0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, data in enumerate(val_loader):\n",
    "\n",
    "            labels = data[:,:,3].to(device).long()\n",
    "\n",
    "            points = data[:,:,0:3].to(device)\n",
    "\n",
    "            seg_results, output = model(points)\n",
    "\n",
    "            rec_loss = rec_criterion(points, output)\n",
    "\n",
    "            seg_loss = seg_criterion( seg_results.view(-1,part_count+1) ,labels.view(-1))\n",
    "\n",
    "            seg_labels = seg_results.argmax(dim=2,keepdim=True).squeeze()\n",
    "            correct = seg_labels.eq(labels.data).cpu().sum()\n",
    "            accuracy = correct.item()/float(data.shape[0]*data.shape[1])\n",
    "\n",
    "            t_rec_loss += rec_loss.item()\n",
    "            t_seg_loss += seg_loss.item()\n",
    "            t_accuracy += accuracy\n",
    "        \n",
    "    return t_rec_loss/(i+1) , t_seg_loss/(i+1), t_accuracy/(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_batch(data): # test with a batch of inputs\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        im_batch = data.to(device)\n",
    "        \n",
    "        output = model(im_batch)\n",
    "\n",
    "    return output.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 --> train:0.003058 test:0.002993 time:26.388:   0%|          | 2/1001 [00:53<7:25:11, 26.74s/it]"
     ]
    }
   ],
   "source": [
    "train_list = []\n",
    "test_list = []\n",
    "\n",
    "pbar = tqdm( range(1001) )\n",
    "for i in pbar :\n",
    "\n",
    "    startTime = time.time()\n",
    "    \n",
    "    train_rec_loss = train_epoch()\n",
    " \n",
    "    test_rec_loss = test_epoch() # test with test set\n",
    "    \n",
    "    epoch_time = time.time() - startTime\n",
    "    \n",
    "    train_list.append(train_rec_loss)\n",
    "    test_list.append(test_rec_loss)\n",
    "    \n",
    "    utils.plot_graph([train_list,test_list], log_folder + \"loss_graph\") # plot loss graph up to that epoch\n",
    "\n",
    "    epoch_time = time.time() - startTime\n",
    "    \n",
    "    writeString = \"epoch %d --> train:%0.6f test:%0.6f time:%0.3f\" % (i, train_rec_loss, test_rec_loss, epoch_time) # generate log string\n",
    "\n",
    "    pbar.set_description(writeString)\n",
    "    log_file.write(writeString + \"\\n\") # write to log file\n",
    "    log_file.flush()\n",
    "    \n",
    "    if(i%10 == 0):\n",
    "        data = next(iter(val_loader))\n",
    "        rec = test_batch(data[0])\n",
    "        \n",
    "        utils.showIMs(data[0], show=False, save=True, name= log_folder +\"ims\" + str(i))\n",
    "        utils.plotPC(rec, show=False, save=True, name= log_folder +\"pcs\" + str(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.cpu().state_dict(), log_folder + \"model_state_dict\")\n",
    "torch.save(model.cpu(), log_folder + \"model_save\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
